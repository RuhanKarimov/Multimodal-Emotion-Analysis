{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49cf272aa2c8d1",
   "metadata": {},
   "source": "1) Config + Seed +  Device"
  },
  {
   "cell_type": "code",
   "id": "a98f048bc13f9b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:27:33.831104Z",
     "start_time": "2025-12-23T07:27:30.443074Z"
    }
   },
   "source": [
    "import os, time, json, random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS\n",
    "# -----------------------------\n",
    "DATASET_ROOT = r\".\\datasetKaggleFER2013\"   # train/ test klasörleri içinde\n",
    "SAVE_DIR = \"./runs_cnn\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# TARGET\n",
    "# -----------------------------\n",
    "EPOCHS = 100               # 40 -> 60/80 genelde 0.70'e iter\n",
    "BATCH  = 256              # VRAM yetmezse 128\n",
    "IMG_SIZE = 224\n",
    "UNFREEZE_EPOCH = 3        # 5 -> 3 (daha erken fine-tune)\n",
    "\n",
    "# imbalance kontrol\n",
    "USE_SAMPLER = True\n",
    "USE_CLASS_WEIGHTS = False # sampler açıksa çoğu zaman kapatılmalı\n",
    "\n",
    "LABEL_SMOOTH = 0.05       # 0.1 -> 0.05 (bazen accuracyyi yükseltir)\n",
    "NUM_WORKERS = 2           # Windows: sorun olursa 0 yapılmalı\n",
    "\n",
    "# Karcı alpha aralığı\n",
    "KARCI_ALPHA = 1.35        # 0.8-1.8 arası, genelde 1.2-1.5 iyi\n",
    "KARCI_CLIP  = 0.10\n",
    "KARCI_EPS   = 1e-3\n",
    "\n",
    "# cudnn speed\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# seed\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Torch: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2) Dataset + Transforms + Loaders + Class weights",
   "id": "c967a02628d5322f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:27:43.132838Z",
     "start_time": "2025-12-23T07:27:43.002050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train transform: daha güçlü augment (FER için işe yarıyor)\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.75, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.25, contrast=0.25)], p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.12), ratio=(0.3, 3.3), value=0.0),\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "train_dir = os.path.join(DATASET_ROOT, \"train\")\n",
    "test_dir  = os.path.join(DATASET_ROOT, \"test\")\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n",
    "test_ds  = datasets.ImageFolder(test_dir,  transform=test_tf)\n",
    "\n",
    "classes = train_ds.classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Train:\", len(train_ds), \"Test:\", len(test_ds))\n",
    "\n",
    "# class counts\n",
    "y_train = np.array([train_ds.targets[i] for i in range(len(train_ds))], dtype=np.int64)\n",
    "counts = np.bincount(y_train, minlength=num_classes).astype(np.float64)\n",
    "\n",
    "# class weights (opsiyonel)\n",
    "class_weights = (counts.sum() / (counts + 1e-9))\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "print(\"Class weights (raw):\", np.round(class_weights, 3))\n",
    "\n",
    "# sampler\n",
    "sampler = None\n",
    "if USE_SAMPLER:\n",
    "    w_per_sample = class_weights[y_train]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.tensor(w_per_sample, dtype=torch.double),\n",
    "        num_samples=len(w_per_sample),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH,\n",
    "    shuffle=(sampler is None),\n",
    "    sampler=sampler,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=(NUM_WORKERS > 0)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=BATCH,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=(NUM_WORKERS > 0)\n",
    ")\n"
   ],
   "id": "575efb0b913a937f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "Train: 28709 Test: 7178\n",
      "Class weights (raw): [0.48  4.398 0.468 0.266 0.386 0.397 0.605]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3) Model(ResNet34) + Freeze/Unfreeze",
   "id": "f9f2169f2adb4a44"
  },
  {
   "cell_type": "code",
   "id": "57eb289c8b20e90d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:27:45.091125Z",
     "start_time": "2025-12-23T07:27:45.084484Z"
    }
   },
   "source": [
    "def build_model(num_classes: int, backbone=\"resnet34\", dropout=0.2):\n",
    "    if backbone == \"resnet18\":\n",
    "        m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        in_feats = m.fc.in_features\n",
    "    elif backbone == \"resnet34\":\n",
    "        m = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        in_feats = m.fc.in_features\n",
    "    else:\n",
    "        raise ValueError(\"backbone must be resnet18 or resnet34\")\n",
    "\n",
    "    # 1 kanal input için conv1 değiştir\n",
    "    old = m.conv1\n",
    "    m.conv1 = nn.Conv2d(\n",
    "        1, old.out_channels,\n",
    "        kernel_size=old.kernel_size,\n",
    "        stride=old.stride,\n",
    "        padding=old.padding,\n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "    # pretrained RGB -> grayscale adapt: ağırlıkları ortalama ile kopyalanır\n",
    "    with torch.no_grad():\n",
    "        m.conv1.weight.copy_(old.weight.mean(dim=1, keepdim=True))\n",
    "\n",
    "    # head\n",
    "    m.fc = nn.Sequential(\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(in_feats, num_classes)\n",
    "    )\n",
    "    return m\n",
    "\n",
    "def freeze_backbone(model):\n",
    "    for name, p in model.named_parameters():\n",
    "        if not name.startswith(\"fc.\"):\n",
    "            p.requires_grad = False\n",
    "\n",
    "def unfreeze_layer4(model):\n",
    "    # resnet layer4 trainable\n",
    "    for name, p in model.named_parameters():\n",
    "        if name.startswith(\"layer4.\") or name.startswith(\"fc.\"):\n",
    "            p.requires_grad = True\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4) Karcı Optimizer(CNN için) + Momentum-Karcı",
   "id": "8bc4c10c7fb8a5bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:27:48.280683Z",
     "start_time": "2025-12-23T07:27:48.261267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "class KarciFANN(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    KarcıFANN update (math aynı):\n",
    "      ratio = (loss+eps) / (wref+eps)\n",
    "      scale = ratio^(alpha-1)\n",
    "      u     = scale * grad\n",
    "      p     = p - lr * clamp(u)\n",
    "\n",
    "    Notlar:\n",
    "    - lr burada klasik LR gibi değil, \"step_scale\" gibi davranır.\n",
    "    - wref: negatif ağırlık gelirse \"önceki pozitif referansı koru\" mantığı.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, alpha=1.30, clip=0.02, eps=1e-3,\n",
    "                 rclip=(1e-3, 1e3), w_floor=1e-2, lr=1.0,\n",
    "                 skip_on_nonfinite=True):\n",
    "        defaults = dict(\n",
    "            alpha=float(alpha),\n",
    "            clip=None if clip is None else float(clip),\n",
    "            eps=float(eps),\n",
    "            rclip=(float(rclip[0]), float(rclip[1])),\n",
    "            w_floor=float(w_floor),\n",
    "            lr=float(lr),\n",
    "            skip_on_nonfinite=bool(skip_on_nonfinite),\n",
    "        )\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "        # state init: wref her param için pozitif tutulur\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            w_floor = group[\"w_floor\"]\n",
    "            for p in group[\"params\"]:\n",
    "                if p.requires_grad:\n",
    "                    st = self.state[p]\n",
    "                    st[\"wref\"] = p.data.abs().clone().add_(eps).clamp_min_(w_floor)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, loss_scalar: float):\n",
    "        # loss_scalar float olmalı (train loop'ta loss.item() veriyoruz)\n",
    "        try:\n",
    "            lossv = float(loss_scalar)\n",
    "        except Exception:\n",
    "            raise ValueError(\"KarcıFANN.step(loss_scalar) için loss_scalar float olmalı (örn: loss.item()).\")\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            alpha = group[\"alpha\"]\n",
    "            clipv = group[\"clip\"]\n",
    "            eps   = group[\"eps\"]\n",
    "            w_floor = group[\"w_floor\"]\n",
    "            lr = group[\"lr\"]\n",
    "            rlo, rhi = group[\"rclip\"]\n",
    "            pwr = alpha - 1.0\n",
    "            skip = group[\"skip_on_nonfinite\"]\n",
    "\n",
    "            # loss NaN/inf ise: ya adım atlanır ya da sabitlenir\n",
    "            if not (lossv == lossv and abs(lossv) != float(\"inf\")):  # NaN/inf check (hızlı)\n",
    "                if skip:\n",
    "                    return None\n",
    "                else:\n",
    "                    lossv = 1.0  # fallback\n",
    "\n",
    "            num = (lossv + eps)  # pozitif\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                g = p.grad\n",
    "                # grad NaN/inf ise temizle (çok önemli)\n",
    "                if not torch.isfinite(g).all():\n",
    "                    if skip:\n",
    "                        # bu paramı güncellenmemeli\n",
    "                        continue\n",
    "                    g = torch.nan_to_num(g, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "                st = self.state[p]\n",
    "                wref = st[\"wref\"]\n",
    "\n",
    "                # wref update: p.data pozitifse güncelleriz, değilse eski wref kalsın\n",
    "                st[\"wref\"] = torch.where(p.data > 0, p.data, wref)\n",
    "\n",
    "                # wref_pos: kesin pozitif, çok küçükse w_floor'a çekeriz\n",
    "                wref_pos = st[\"wref\"].abs().clamp_min_(w_floor)\n",
    "\n",
    "                # ratio kesin pozitif\n",
    "                ratio = (num / (wref_pos + eps)).clamp_(min=rlo, max=rhi)\n",
    "\n",
    "                # scale = ratio^(alpha-1)  (ratio>0 => NaN üretmez)\n",
    "                scale = ratio.pow(pwr)\n",
    "\n",
    "                # u = scale * grad\n",
    "                u = scale * g\n",
    "\n",
    "                # elementwise clip: patlamayı engeller\n",
    "                if clipv is not None:\n",
    "                    u = u.clamp_(min=-clipv, max=clipv)\n",
    "\n",
    "                # param update\n",
    "                p.data.add_(-lr * u)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "class MomentumKarci(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Momentum-Karcı:\n",
    "      u = ((loss+eps)/(wref+eps))^(alpha-1) * grad\n",
    "      v = beta*v + u\n",
    "      p = p - lr*v\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, alpha=1.30, beta=0.90, clip=0.02, eps=1e-3,\n",
    "                 rclip=(1e-3, 1e3), w_floor=1e-2, lr=1.0,\n",
    "                 skip_on_nonfinite=True):\n",
    "        defaults = dict(\n",
    "            alpha=float(alpha),\n",
    "            beta=float(beta),\n",
    "            clip=None if clip is None else float(clip),\n",
    "            eps=float(eps),\n",
    "            rclip=(float(rclip[0]), float(rclip[1])),\n",
    "            w_floor=float(w_floor),\n",
    "            lr=float(lr),\n",
    "            skip_on_nonfinite=bool(skip_on_nonfinite),\n",
    "        )\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            eps = group[\"eps\"]\n",
    "            w_floor = group[\"w_floor\"]\n",
    "            for p in group[\"params\"]:\n",
    "                if p.requires_grad:\n",
    "                    st = self.state[p]\n",
    "                    st[\"wref\"] = p.data.abs().clone().add_(eps).clamp_min_(w_floor)\n",
    "                    st[\"v\"] = torch.zeros_like(p.data)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, loss_scalar: float):\n",
    "        try:\n",
    "            lossv = float(loss_scalar)\n",
    "        except Exception:\n",
    "            raise ValueError(\"MomentumKarci.step(loss_scalar) için loss_scalar float olmalı (örn: loss.item()).\")\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            alpha = group[\"alpha\"]\n",
    "            beta  = group[\"beta\"]\n",
    "            clipv = group[\"clip\"]\n",
    "            eps   = group[\"eps\"]\n",
    "            w_floor = group[\"w_floor\"]\n",
    "            lr = group[\"lr\"]\n",
    "            rlo, rhi = group[\"rclip\"]\n",
    "            pwr = alpha - 1.0\n",
    "            skip = group[\"skip_on_nonfinite\"]\n",
    "\n",
    "            if not (lossv == lossv and abs(lossv) != float(\"inf\")):\n",
    "                if skip:\n",
    "                    return None\n",
    "                else:\n",
    "                    lossv = 1.0\n",
    "\n",
    "            num = (lossv + eps)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                g = p.grad\n",
    "                if not torch.isfinite(g).all():\n",
    "                    if skip:\n",
    "                        continue\n",
    "                    g = torch.nan_to_num(g, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "                st = self.state[p]\n",
    "\n",
    "                st[\"wref\"] = torch.where(p.data > 0, p.data, st[\"wref\"])\n",
    "                wref_pos = st[\"wref\"].abs().clamp_min_(w_floor)\n",
    "\n",
    "                ratio = (num / (wref_pos + eps)).clamp_(min=rlo, max=rhi)\n",
    "                scale = ratio.pow(pwr)\n",
    "\n",
    "                u = scale * g\n",
    "                if clipv is not None:\n",
    "                    u = u.clamp_(min=-clipv, max=clipv)\n",
    "\n",
    "                st[\"v\"].mul_(beta).add_(u)\n",
    "                p.data.add_(-lr * st[\"v\"])\n",
    "\n",
    "        return None\n"
   ],
   "id": "cbe601137691b61d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5) Optimizer factory + Loss",
   "id": "a87872222d4f070e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:27:53.716814Z",
     "start_time": "2025-12-23T07:27:53.702775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_optimizer(opt_name, model, backbone_lr=3e-4, head_lr=3e-3, weight_decay=0.01):\n",
    "    backbone_params = []\n",
    "    head_params = []\n",
    "    for name, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if name.startswith(\"fc.\"):\n",
    "            head_params.append(p)\n",
    "        else:\n",
    "            backbone_params.append(p)\n",
    "\n",
    "    if opt_name == \"adamw\":\n",
    "        return torch.optim.AdamW(\n",
    "            [{\"params\": backbone_params, \"lr\": backbone_lr},\n",
    "             {\"params\": head_params,     \"lr\": head_lr}],\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    if opt_name == \"sgd\":\n",
    "        return torch.optim.SGD(\n",
    "            [{\"params\": backbone_params, \"lr\": backbone_lr},\n",
    "             {\"params\": head_params,     \"lr\": head_lr}],\n",
    "            momentum=0.9, nesterov=True, weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    if opt_name == \"karci\":\n",
    "        return KarciFANN(\n",
    "            [{\"params\": backbone_params},\n",
    "             {\"params\": head_params}],\n",
    "            alpha=KARCI_ALPHA, clip=KARCI_CLIP, eps=KARCI_EPS\n",
    "        )\n",
    "\n",
    "    if opt_name == \"mkarci\":\n",
    "        return MomentumKarci(\n",
    "            [{\"params\": backbone_params},\n",
    "             {\"params\": head_params}],\n",
    "            alpha=KARCI_ALPHA, beta=0.85, clip=KARCI_CLIP, eps=KARCI_EPS\n",
    "        )\n",
    "\n",
    "    raise ValueError(\"opt_name must be one of: adamw, sgd, karci, mkarci\")\n",
    "\n",
    "# loss\n",
    "cw = None\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    cw = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=cw, label_smoothing=LABEL_SMOOTH)\n"
   ],
   "id": "d032e95c1ceaba47",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6)Train/Eval(AMP doğru kullanımı + scheduler sırası düzeltildi)",
   "id": "9a6f11bfab058147"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:27:55.827069Z",
     "start_time": "2025-12-23T07:27:55.804149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# device (zaten tanımlıysa sorun değil)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# Tek scaler (CPU'da otomatik disable)\n",
    "scaler_amp = torch.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "            logits = model(xb)\n",
    "\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        ys.append(yb.detach().cpu().numpy())\n",
    "        ps.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    y = np.concatenate(ys)\n",
    "    p = np.concatenate(ps)\n",
    "    return float(accuracy_score(y, p)), y, p\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion,\n",
    "                    scheduler=None, karci=False, grad_clip=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # forward + loss (AMP)\n",
    "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "        # loss NaN/Inf ise batch'i atlarız (Karcı NaN zincirini kesmek için çok önemli)\n",
    "        if not torch.isfinite(loss):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            continue\n",
    "\n",
    "        # backward (scaled)\n",
    "        scaler_amp.scale(loss).backward()\n",
    "\n",
    "        # unscale -> clip doğru çalışsın\n",
    "        scaler_amp.unscale_(optimizer)\n",
    "\n",
    "        # gradient NaN/Inf kontrolü (özellikle Karcı'da patlama olursa)\n",
    "        if grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        # optimizer step\n",
    "        if karci:\n",
    "            # Karcı optimizer step(loss_scalar) imzası\n",
    "            optimizer.step(float(loss.detach().item()))\n",
    "        else:\n",
    "            scaler_amp.step(optimizer)\n",
    "\n",
    "        scaler_amp.update()\n",
    "\n",
    "        # OneCycle gibi scheduler'lar batch başına step ister\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        bs = xb.size(0)\n",
    "        total_loss += float(loss.detach().item()) * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / max(1, n)\n"
   ],
   "id": "baff6d72bd344fc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7)Tek optimizer çalıştırma(her biri ayrı kayıt) + OneCycleLR fix(cycle_momentum)",
   "id": "c3f760604a514987"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:27:59.524470Z",
     "start_time": "2025-12-23T07:27:59.512078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, time, json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def train_one_optimizer(opt_name, backbone=\"resnet34\"):\n",
    "    run_dir = os.path.join(SAVE_DIR, opt_name)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    model = build_model(num_classes, backbone=backbone, dropout=0.2).to(device)\n",
    "    freeze_backbone(model)\n",
    "\n",
    "    optimizer = make_optimizer(opt_name, model)\n",
    "\n",
    "    # OneCycleLR sadece adamw/sgd için (Karcı'da genelde kapalı daha stabil)\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    use_scheduler = opt_name in (\"adamw\", \"sgd\")\n",
    "    scheduler = None\n",
    "\n",
    "    if use_scheduler:\n",
    "        max_lrs = [pg.get(\"lr\", 3e-4) for pg in optimizer.param_groups]\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=max_lrs,\n",
    "            epochs=EPOCHS,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            pct_start=0.15,\n",
    "            div_factor=10.0,\n",
    "            final_div_factor=50.0,\n",
    "            cycle_momentum=(opt_name == \"sgd\")\n",
    "        )\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_ep = -1\n",
    "    best_path = None\n",
    "    did_unfreeze = False\n",
    "    history = {\"train_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for ep in range(1, EPOCHS + 1):\n",
    "\n",
    "        # ---- unfreeze ----\n",
    "        if (not did_unfreeze) and (ep == UNFREEZE_EPOCH):\n",
    "            did_unfreeze = True\n",
    "            print(f\"[{opt_name.upper()}] Unfreeze layer4 at epoch {ep}\")\n",
    "\n",
    "            unfreeze_layer4(model)\n",
    "            optimizer = make_optimizer(opt_name, model)\n",
    "\n",
    "            # scheduler yeniden kurulur (optimizer değişti)\n",
    "            if opt_name in (\"adamw\", \"sgd\"):\n",
    "                max_lrs = [pg.get(\"lr\", 3e-4) for pg in optimizer.param_groups]\n",
    "                scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                    optimizer,\n",
    "                    max_lr=max_lrs,\n",
    "                    epochs=EPOCHS-ep+1,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    pct_start=0.15,\n",
    "                    div_factor=10.0,\n",
    "                    final_div_factor=50.0,\n",
    "                    cycle_momentum=(opt_name == \"sgd\")\n",
    "                )\n",
    "\n",
    "            print(\"Trainable params:\", count_trainable_params(model))\n",
    "\n",
    "        t0 = time.time()\n",
    "        karci_mode = opt_name in (\"karci\", \"mkarci\")\n",
    "\n",
    "        tr_loss = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion,\n",
    "            scheduler=scheduler, karci=karci_mode, grad_clip=1.0\n",
    "        )\n",
    "\n",
    "        acc, y_true, y_pred = evaluate(model, test_loader)\n",
    "\n",
    "        history[\"train_loss\"].append(float(tr_loss))\n",
    "        history[\"test_acc\"].append(float(acc))\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = float(acc)\n",
    "            best_ep  = int(ep)\n",
    "            best_path = os.path.join(run_dir, f\"best_{opt_name}.pt\")\n",
    "            NORM_CFG = {\n",
    "    \"mode\": \"gray\",\n",
    "    \"scale\": \"0_1\",\n",
    "    \"mean\": [0.5],\n",
    "    \"std\":  [0.5],\n",
    "    \"channels\": 1\n",
    "}\n",
    "            torch.save({\n",
    "    \"epoch\": best_ep,\n",
    "    \"acc\": best_acc,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_name\": opt_name,\n",
    "    \"classes\": classes,\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"backbone\": backbone,\n",
    "\n",
    "    # >>> BUNLAR ÇOK KRİTİK:\n",
    "    \"norm\": NORM_CFG,\n",
    "    \"input_channels\": 1,\n",
    "    \"face_crop\": True,   # webcam tarafında da yapacağız\n",
    "\n",
    "    \"history\": history\n",
    "}, best_path)\n",
    "\n",
    "\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        lr_back = optimizer.param_groups[0].get(\"lr\", None)\n",
    "        lr_head = optimizer.param_groups[-1].get(\"lr\", None)\n",
    "\n",
    "        print(f\"[{opt_name.upper()}] ep={ep:3d} loss={tr_loss:.4f} acc={acc:.3f} \"\n",
    "              f\"| best={best_acc:.3f}@{best_ep} | lr(back)={lr_back} lr(head)={lr_head} ({dt:.1f}s)\")\n",
    "\n",
    "    # ---- BEST confusion ----\n",
    "    ckpt = torch.load(best_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    acc_best, y_true, y_pred = evaluate(model, test_loader)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(\"\\nBest:\", best_acc, \"@epoch\", best_ep, \"path:\", best_path)\n",
    "    print(f\"Confusion Matrix (BEST @{ckpt['epoch']} acc={acc_best:.4f}):\\n\", cm)\n",
    "\n",
    "    meta = {\n",
    "        \"optimizer\": opt_name,\n",
    "        \"epochs\": int(EPOCHS),\n",
    "        \"unfreeze_epoch\": int(UNFREEZE_EPOCH),\n",
    "        \"batch\": int(BATCH),\n",
    "        \"img_size\": int(IMG_SIZE),\n",
    "        \"use_sampler\": bool(USE_SAMPLER),\n",
    "        \"use_class_weights\": bool(USE_CLASS_WEIGHTS),\n",
    "        \"label_smoothing\": float(LABEL_SMOOTH),\n",
    "        \"karci_alpha\": float(KARCI_ALPHA) if opt_name in (\"karci\",\"mkarci\") else None,\n",
    "        \"best_acc\": float(best_acc),\n",
    "        \"best_epoch\": int(best_ep),\n",
    "        \"classes\": list(map(str, classes)),\n",
    "        \"best_path\": best_path,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(run_dir, f\"{opt_name}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"Saved:\", os.path.join(run_dir, f\"{opt_name}.json\"))\n",
    "    return meta\n"
   ],
   "id": "e94efd6cc8276c8a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "8)Compare: AdamW + SGD + Karcı + Momentum-Karcı ve hepsini kaydederiz",
   "id": "72ede406cd076c53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "opts = [\"adamw\", \"sgd\", \"karci\", \"mkarci\"]  # istediğimizi çıkarıp ekleriz\n",
    "results = []\n",
    "\n",
    "for opt in opts:\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"RUN:\", opt)\n",
    "    print(\"=\"*90)\n",
    "    meta = train_one_optimizer(opt_name=opt, backbone=\"resnet34\")\n",
    "    results.append(meta)\n",
    "\n",
    "# overall best\n",
    "best = max(results, key=lambda x: x[\"best_acc\"])\n",
    "with open(os.path.join(SAVE_DIR, \"best_overall.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nBEST OVERALL:\", best[\"optimizer\"], \"acc=\", best[\"best_acc\"], \"path=\", best[\"best_path\"])\n",
    "print(\"Saved:\", os.path.join(SAVE_DIR, \"best_overall.json\"))\n"
   ],
   "id": "d23c3ad72474ef68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "9) Hepsini sırayla çalıştırırız (adamw/sgd/karci/mkarci)",
   "id": "ba03c5dcba901ae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T23:13:30.796205Z",
     "start_time": "2025-12-21T21:32:13.151829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#opts = [\"adamw\", \"sgd\", \"karci\", \"mkarci\"]  # istediğimizi çıkarıp ekleriz\n",
    "opts = [\"karci\", \"mkarci\"]  # istediğimizi çıkarıp ekleriz\n",
    "results = []\n",
    "\n",
    "for opt in opts:\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"RUN:\", opt)\n",
    "    print(\"=\"*90)\n",
    "    meta = train_one_optimizer(opt_name=opt, backbone=\"resnet34\")\n",
    "    results.append(meta)\n",
    "\n",
    "# overall best\n",
    "best = max(results, key=lambda x: x[\"best_acc\"])\n",
    "with open(os.path.join(SAVE_DIR, \"best_overall.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(best, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nBEST OVERALL:\", best[\"optimizer\"], \"acc=\", best[\"best_acc\"], \"path=\", best[\"best_path\"])\n",
    "print(\"Saved:\", os.path.join(SAVE_DIR, \"best_overall.json\"))\n"
   ],
   "id": "fa1fa914359c2011",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "RUN: karci\n",
      "==========================================================================================\n",
      "[KARCI] ep=  1 loss=21.2777 acc=0.174 | best=0.174@1 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[KARCI] ep=  2 loss=17.6863 acc=0.176 | best=0.176@2 | lr(back)=1.0 lr(head)=1.0 (26.6s)\n",
      "[KARCI] Unfreeze layer4 at epoch 3\n",
      "Trainable params: 13117959\n",
      "[KARCI] ep=  3 loss=3.1683 acc=0.236 | best=0.236@3 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep=  4 loss=1.3917 acc=0.373 | best=0.373@4 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep=  5 loss=1.2269 acc=0.513 | best=0.513@5 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep=  6 loss=1.1485 acc=0.316 | best=0.513@5 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep=  7 loss=1.0884 acc=0.534 | best=0.534@7 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep=  8 loss=1.0427 acc=0.498 | best=0.534@7 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep=  9 loss=1.0115 acc=0.551 | best=0.551@9 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 10 loss=0.9867 acc=0.554 | best=0.554@10 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 11 loss=0.9618 acc=0.565 | best=0.565@11 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 12 loss=0.9451 acc=0.387 | best=0.565@11 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 13 loss=0.9095 acc=0.528 | best=0.565@11 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 14 loss=0.9072 acc=0.553 | best=0.565@11 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 15 loss=0.8847 acc=0.571 | best=0.571@15 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 16 loss=0.8694 acc=0.511 | best=0.571@15 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 17 loss=0.8497 acc=0.494 | best=0.571@15 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 18 loss=0.8318 acc=0.479 | best=0.571@15 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 19 loss=0.8166 acc=0.615 | best=0.615@19 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 20 loss=0.7941 acc=0.598 | best=0.615@19 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 21 loss=0.7887 acc=0.525 | best=0.615@19 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 22 loss=0.7652 acc=0.621 | best=0.621@22 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 23 loss=0.7560 acc=0.590 | best=0.621@22 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 24 loss=0.7463 acc=0.608 | best=0.621@22 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 25 loss=0.7303 acc=0.639 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 26 loss=0.7200 acc=0.577 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 27 loss=0.7042 acc=0.559 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 28 loss=0.6867 acc=0.575 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 29 loss=0.6855 acc=0.618 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 30 loss=0.6733 acc=0.631 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 31 loss=0.6620 acc=0.622 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 32 loss=0.6585 acc=0.567 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 33 loss=0.6419 acc=0.559 | best=0.639@25 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 34 loss=0.6403 acc=0.645 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 35 loss=0.6181 acc=0.606 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 36 loss=0.6123 acc=0.641 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 37 loss=0.6102 acc=0.643 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 38 loss=0.5930 acc=0.616 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 39 loss=0.5932 acc=0.623 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 40 loss=0.5875 acc=0.614 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.2s)\n",
      "[KARCI] ep= 41 loss=0.5799 acc=0.628 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 42 loss=0.5707 acc=0.574 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 43 loss=0.5668 acc=0.637 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 44 loss=0.5621 acc=0.625 | best=0.645@34 | lr(back)=1.0 lr(head)=1.0 (31.2s)\n",
      "[KARCI] ep= 45 loss=0.5541 acc=0.651 | best=0.651@45 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 46 loss=0.5460 acc=0.557 | best=0.651@45 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 47 loss=0.5393 acc=0.628 | best=0.651@45 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 48 loss=0.5410 acc=0.641 | best=0.651@45 | lr(back)=1.0 lr(head)=1.0 (31.2s)\n",
      "[KARCI] ep= 49 loss=0.5346 acc=0.620 | best=0.651@45 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 50 loss=0.5258 acc=0.652 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 51 loss=0.5206 acc=0.643 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.2s)\n",
      "[KARCI] ep= 52 loss=0.5192 acc=0.638 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.2s)\n",
      "[KARCI] ep= 53 loss=0.5109 acc=0.642 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[KARCI] ep= 54 loss=0.5106 acc=0.635 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.3s)\n",
      "[KARCI] ep= 55 loss=0.5044 acc=0.610 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 56 loss=0.4897 acc=0.643 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.2s)\n",
      "[KARCI] ep= 57 loss=0.5008 acc=0.646 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (31.4s)\n",
      "[KARCI] ep= 58 loss=0.4934 acc=0.620 | best=0.652@50 | lr(back)=1.0 lr(head)=1.0 (32.4s)\n",
      "[KARCI] ep= 59 loss=0.4917 acc=0.653 | best=0.653@59 | lr(back)=1.0 lr(head)=1.0 (32.1s)\n",
      "[KARCI] ep= 60 loss=0.4814 acc=0.647 | best=0.653@59 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 61 loss=0.4843 acc=0.644 | best=0.653@59 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 62 loss=0.4822 acc=0.653 | best=0.653@59 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 63 loss=0.4738 acc=0.643 | best=0.653@59 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 64 loss=0.4735 acc=0.661 | best=0.661@64 | lr(back)=1.0 lr(head)=1.0 (31.9s)\n",
      "[KARCI] ep= 65 loss=0.4667 acc=0.645 | best=0.661@64 | lr(back)=1.0 lr(head)=1.0 (31.9s)\n",
      "[KARCI] ep= 66 loss=0.4679 acc=0.661 | best=0.661@64 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 67 loss=0.4662 acc=0.664 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 68 loss=0.4618 acc=0.654 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (32.1s)\n",
      "[KARCI] ep= 69 loss=0.4528 acc=0.642 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 70 loss=0.4505 acc=0.635 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 71 loss=0.4499 acc=0.659 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 72 loss=0.4507 acc=0.622 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 73 loss=0.4466 acc=0.654 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 74 loss=0.4409 acc=0.658 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 75 loss=0.4420 acc=0.658 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 76 loss=0.4443 acc=0.643 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 77 loss=0.4423 acc=0.647 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 78 loss=0.4346 acc=0.652 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 79 loss=0.4403 acc=0.656 | best=0.664@67 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 80 loss=0.4280 acc=0.667 | best=0.667@80 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 81 loss=0.4250 acc=0.655 | best=0.667@80 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 82 loss=0.4243 acc=0.659 | best=0.667@80 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 83 loss=0.4253 acc=0.655 | best=0.667@80 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 84 loss=0.4255 acc=0.651 | best=0.667@80 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 85 loss=0.4261 acc=0.667 | best=0.667@85 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 86 loss=0.4207 acc=0.663 | best=0.667@85 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 87 loss=0.4202 acc=0.656 | best=0.667@85 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 88 loss=0.4201 acc=0.657 | best=0.667@85 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 89 loss=0.4131 acc=0.675 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 90 loss=0.4098 acc=0.670 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 91 loss=0.4151 acc=0.654 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 92 loss=0.4061 acc=0.673 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 93 loss=0.4104 acc=0.667 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 94 loss=0.4139 acc=0.666 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep= 95 loss=0.4068 acc=0.668 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 96 loss=0.4042 acc=0.656 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 97 loss=0.4020 acc=0.668 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[KARCI] ep= 98 loss=0.4053 acc=0.654 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[KARCI] ep= 99 loss=0.4014 acc=0.649 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[KARCI] ep=100 loss=0.3945 acc=0.655 | best=0.675@89 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "\n",
      "Best: 0.6748397882418501 @epoch 89 path: ./runs_cnn\\karci\\best_karci.pt\n",
      "Confusion Matrix (BEST @89 acc=0.6748):\n",
      " [[ 618    6   75   56   75  111   17]\n",
      " [  19   76    2    5    6    2    1]\n",
      " [ 136    0  486   54  105  178   65]\n",
      " [  48    2   26 1555   77   35   31]\n",
      " [  98    5   53  134  777  151   15]\n",
      " [ 144    2  112  108  205  661   15]\n",
      " [  29    0   46   45   24   16  671]]\n",
      "Saved: ./runs_cnn\\karci\\karci.json\n",
      "\n",
      "==========================================================================================\n",
      "RUN: mkarci\n",
      "==========================================================================================\n",
      "[MKARCI] ep=  1 loss=36.5385 acc=0.299 | best=0.299@1 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[MKARCI] ep=  2 loss=17.1801 acc=0.216 | best=0.299@1 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] Unfreeze layer4 at epoch 3\n",
      "Trainable params: 13117959\n",
      "[MKARCI] ep=  3 loss=3.3148 acc=0.412 | best=0.412@3 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[MKARCI] ep=  4 loss=1.4603 acc=0.476 | best=0.476@4 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[MKARCI] ep=  5 loss=1.3254 acc=0.536 | best=0.536@5 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep=  6 loss=1.2640 acc=0.512 | best=0.536@5 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep=  7 loss=1.2017 acc=0.565 | best=0.565@7 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[MKARCI] ep=  8 loss=1.1523 acc=0.598 | best=0.598@8 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[MKARCI] ep=  9 loss=1.1168 acc=0.579 | best=0.598@8 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 10 loss=1.0916 acc=0.573 | best=0.598@8 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 11 loss=1.0833 acc=0.609 | best=0.609@11 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 12 loss=1.0483 acc=0.617 | best=0.617@12 | lr(back)=1.0 lr(head)=1.0 (31.9s)\n",
      "[MKARCI] ep= 13 loss=1.0313 acc=0.616 | best=0.617@12 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 14 loss=1.0266 acc=0.601 | best=0.617@12 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[MKARCI] ep= 15 loss=1.0048 acc=0.605 | best=0.617@12 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 16 loss=0.9919 acc=0.627 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 17 loss=0.9790 acc=0.601 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 18 loss=0.9704 acc=0.623 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 19 loss=0.9544 acc=0.620 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 20 loss=0.9501 acc=0.621 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 21 loss=0.9312 acc=0.621 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 22 loss=0.9252 acc=0.625 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 23 loss=0.9147 acc=0.605 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 24 loss=0.8976 acc=0.613 | best=0.627@16 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 25 loss=0.8938 acc=0.627 | best=0.627@25 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[MKARCI] ep= 26 loss=0.8940 acc=0.612 | best=0.627@25 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 27 loss=0.8774 acc=0.630 | best=0.630@27 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 28 loss=0.8661 acc=0.636 | best=0.636@28 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 29 loss=0.8637 acc=0.630 | best=0.636@28 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 30 loss=0.8594 acc=0.633 | best=0.636@28 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 31 loss=0.8547 acc=0.629 | best=0.636@28 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 32 loss=0.8400 acc=0.646 | best=0.646@32 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 33 loss=0.8315 acc=0.643 | best=0.646@32 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 34 loss=0.8392 acc=0.650 | best=0.650@34 | lr(back)=1.0 lr(head)=1.0 (31.7s)\n",
      "[MKARCI] ep= 35 loss=0.8264 acc=0.633 | best=0.650@34 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[MKARCI] ep= 36 loss=0.8132 acc=0.648 | best=0.650@34 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 37 loss=0.8066 acc=0.649 | best=0.650@34 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[MKARCI] ep= 38 loss=0.8001 acc=0.643 | best=0.650@34 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[MKARCI] ep= 39 loss=0.7908 acc=0.616 | best=0.650@34 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[MKARCI] ep= 40 loss=0.7838 acc=0.654 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (31.9s)\n",
      "[MKARCI] ep= 41 loss=0.7757 acc=0.605 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 42 loss=0.7756 acc=0.653 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 43 loss=0.7695 acc=0.639 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (31.5s)\n",
      "[MKARCI] ep= 44 loss=0.7549 acc=0.651 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (32.0s)\n",
      "[MKARCI] ep= 45 loss=0.7601 acc=0.650 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (32.0s)\n",
      "[MKARCI] ep= 46 loss=0.7511 acc=0.642 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (31.8s)\n",
      "[MKARCI] ep= 47 loss=0.7492 acc=0.630 | best=0.654@40 | lr(back)=1.0 lr(head)=1.0 (33.0s)\n",
      "[MKARCI] ep= 48 loss=0.7433 acc=0.657 | best=0.657@48 | lr(back)=1.0 lr(head)=1.0 (32.4s)\n",
      "[MKARCI] ep= 49 loss=0.7392 acc=0.657 | best=0.657@48 | lr(back)=1.0 lr(head)=1.0 (32.0s)\n",
      "[MKARCI] ep= 50 loss=0.7301 acc=0.647 | best=0.657@48 | lr(back)=1.0 lr(head)=1.0 (30.7s)\n",
      "[MKARCI] ep= 51 loss=0.7364 acc=0.659 | best=0.659@51 | lr(back)=1.0 lr(head)=1.0 (31.6s)\n",
      "[MKARCI] ep= 52 loss=0.7114 acc=0.645 | best=0.659@51 | lr(back)=1.0 lr(head)=1.0 (27.2s)\n",
      "[MKARCI] ep= 53 loss=0.7042 acc=0.661 | best=0.661@53 | lr(back)=1.0 lr(head)=1.0 (27.1s)\n",
      "[MKARCI] ep= 54 loss=0.7059 acc=0.652 | best=0.661@53 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 55 loss=0.7081 acc=0.643 | best=0.661@53 | lr(back)=1.0 lr(head)=1.0 (27.0s)\n",
      "[MKARCI] ep= 56 loss=0.6964 acc=0.629 | best=0.661@53 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 57 loss=0.6960 acc=0.662 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (27.0s)\n",
      "[MKARCI] ep= 58 loss=0.6858 acc=0.647 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 59 loss=0.6861 acc=0.644 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 60 loss=0.6720 acc=0.651 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 61 loss=0.6754 acc=0.654 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 62 loss=0.6702 acc=0.646 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 63 loss=0.6648 acc=0.655 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 64 loss=0.6654 acc=0.635 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[MKARCI] ep= 65 loss=0.6568 acc=0.654 | best=0.662@57 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 66 loss=0.6540 acc=0.666 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 67 loss=0.6447 acc=0.658 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 68 loss=0.6460 acc=0.637 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 69 loss=0.6375 acc=0.654 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 70 loss=0.6401 acc=0.658 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 71 loss=0.6368 acc=0.643 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (27.0s)\n",
      "[MKARCI] ep= 72 loss=0.6276 acc=0.665 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 73 loss=0.6240 acc=0.657 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 74 loss=0.6169 acc=0.648 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 75 loss=0.6129 acc=0.649 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[MKARCI] ep= 76 loss=0.6184 acc=0.659 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[MKARCI] ep= 77 loss=0.6119 acc=0.656 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 78 loss=0.6035 acc=0.655 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 79 loss=0.6003 acc=0.643 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[MKARCI] ep= 80 loss=0.5999 acc=0.662 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 81 loss=0.5883 acc=0.664 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 82 loss=0.5919 acc=0.649 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 83 loss=0.5851 acc=0.643 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 84 loss=0.5882 acc=0.654 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 85 loss=0.5777 acc=0.654 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[MKARCI] ep= 86 loss=0.5896 acc=0.648 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 87 loss=0.5755 acc=0.661 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 88 loss=0.5758 acc=0.661 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 89 loss=0.5724 acc=0.661 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 90 loss=0.5639 acc=0.658 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 91 loss=0.5607 acc=0.659 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 92 loss=0.5693 acc=0.658 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 93 loss=0.5621 acc=0.658 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.9s)\n",
      "[MKARCI] ep= 94 loss=0.5612 acc=0.654 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 95 loss=0.5529 acc=0.647 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 96 loss=0.5574 acc=0.660 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.7s)\n",
      "[MKARCI] ep= 97 loss=0.5521 acc=0.655 | best=0.666@66 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 98 loss=0.5421 acc=0.668 | best=0.668@98 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep= 99 loss=0.5485 acc=0.654 | best=0.668@98 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "[MKARCI] ep=100 loss=0.5487 acc=0.667 | best=0.668@98 | lr(back)=1.0 lr(head)=1.0 (26.8s)\n",
      "\n",
      "Best: 0.6678740596266369 @epoch 98 path: ./runs_cnn\\mkarci\\best_mkarci.pt\n",
      "Confusion Matrix (BEST @98 acc=0.6679):\n",
      " [[ 554    7   75   73  122   96   31]\n",
      " [  22   76    3    3    6    0    1]\n",
      " [ 132    4  477   59  147  138   67]\n",
      " [  26    0   18 1577   98   16   39]\n",
      " [  65    2   55   95  890  110   16]\n",
      " [ 148    7  118  115  308  534   17]\n",
      " [  26    0   40   34   33   12  686]]\n",
      "Saved: ./runs_cnn\\mkarci\\mkarci.json\n",
      "\n",
      "BEST OVERALL: karci acc= 0.6748397882418501 path= ./runs_cnn\\karci\\best_karci.pt\n",
      "Saved: ./runs_cnn\\best_overall.json\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:28:36.810932Z",
     "start_time": "2025-12-23T07:28:36.781613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2, torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "FACE_CASCADE = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def load_checkpoint(pt_path):\n",
    "    ckpt = torch.load(pt_path, map_location=device)\n",
    "    model = build_model(num_classes, backbone=ckpt.get(\"backbone\",\"resnet34\"), dropout=0.0).to(device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "    return model, ckpt\n",
    "\n",
    "def get_face_crop(frame_bgr):\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    faces = FACE_CASCADE.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(60, 60))\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    # en büyük yüzü seçelim\n",
    "    x,y,w,h = sorted(faces, key=lambda b: b[2]*b[3], reverse=True)[0]\n",
    "    pad = int(0.15 * max(w,h))\n",
    "    x0 = max(0, x-pad); y0 = max(0, y-pad)\n",
    "    x1 = min(frame_bgr.shape[1], x+w+pad); y1 = min(frame_bgr.shape[0], y+h+pad)\n",
    "    return frame_bgr[y0:y1, x0:x1]\n",
    "\n",
    "def preprocess_frame(frame_bgr, img_size, norm_cfg=None):\n",
    "    # yüz crop varsa onu kullanalım\n",
    "    face = get_face_crop(frame_bgr)\n",
    "    if face is None:\n",
    "        face = frame_bgr  # yüz bulunamazsa full frame (ama bu daha kötü olur)\n",
    "\n",
    "    gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "    img  = cv2.resize(gray, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    x = torch.from_numpy(img).float() / 255.0  # [H,W] 0..1\n",
    "\n",
    "    # norm cfg\n",
    "    if norm_cfg is None:\n",
    "        mean, std = 0.5, 0.5\n",
    "    else:\n",
    "        mean = float(norm_cfg.get(\"mean\", [0.5])[0])\n",
    "        std  = float(norm_cfg.get(\"std\",  [0.5])[0])\n",
    "\n",
    "    x = (x - mean) / (std + 1e-8)\n",
    "\n",
    "    x = x.unsqueeze(0).unsqueeze(0)  # [1,1,H,W]\n",
    "    return x.to(device)\n"
   ],
   "id": "2a820357d80e0360",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "9) Webcam demo (tek model)",
   "id": "558e7070d143c88c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:28:55.685402Z",
     "start_time": "2025-12-23T07:28:38.901733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "def load_checkpoint(pt_path):\n",
    "    ckpt = torch.load(pt_path, map_location=device)\n",
    "    model = build_model(num_classes, backbone=ckpt.get(\"backbone\",\"resnet34\"), dropout=0.0).to(device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "    return model, ckpt\n",
    "\n",
    "# aynı normalize ile preprocess\n",
    "def preprocess_frame_bgr(frame_bgr):\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(gray, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    x = torch.from_numpy(img).float() / 255.0\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = x.unsqueeze(0).unsqueeze(0)  # [1,1,H,W]\n",
    "    return x.to(device)\n",
    "\n",
    "def webcam_run(pt_path, cam_id=0):\n",
    "    model, ckpt = load_checkpoint(pt_path)\n",
    "    cls = ckpt[\"classes\"]\n",
    "\n",
    "    cap = cv2.VideoCapture(cam_id)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Webcam açılamadı. cam_id değiştir: 0/1/2 deneyebilirsin.\")\n",
    "\n",
    "    print(\"ESC ile çıkış.\")\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        x = preprocess_frame_bgr(frame)\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            prob = torch.softmax(logits, dim=1)[0].detach().cpu().numpy()\n",
    "            pred = int(prob.argmax())\n",
    "\n",
    "        text = f\"{cls[pred]} ({prob[pred]*100:.1f}%)\"\n",
    "        cv2.putText(frame, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,0), 2)\n",
    "\n",
    "        cv2.imshow(\"FER live\", frame)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:  # ESC\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "webcam_run(r\".\\runs_cnn\\adamw\\best_adamw.pt\")\n"
   ],
   "id": "d8066032c57603ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC ile çıkış.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "10) İki modeli aynı anda kıyas (A/B)",
   "id": "fd4a06cad58b753d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T07:30:57.526013Z",
     "start_time": "2025-12-23T07:29:00.673833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def webcam_compare(ptA, ptB, cam_id=0, conf_thr=0.35):\n",
    "    modelA, ckptA = load_checkpoint(ptA)\n",
    "    modelB, ckptB = load_checkpoint(ptB)\n",
    "\n",
    "    clsA = ckptA.get(\"classes\", None)\n",
    "    clsB = ckptB.get(\"classes\", None)\n",
    "\n",
    "    img_sizeA = int(ckptA.get(\"img_size\", 224))\n",
    "    img_sizeB = int(ckptB.get(\"img_size\", 224))\n",
    "\n",
    "    normA = ckptA.get(\"norm\", None)\n",
    "    normB = ckptB.get(\"norm\", None)\n",
    "\n",
    "    cap = cv2.VideoCapture(cam_id)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Webcam açılamadı. cam_id=0/1 deneyebilirsin.\")\n",
    "\n",
    "    print(\"ESC çıkış.\")\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        xA = preprocess_frame(frame, img_sizeA, normA)\n",
    "        xB = preprocess_frame(frame, img_sizeB, normB)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pA = torch.softmax(modelA(xA), dim=1)[0]\n",
    "            pB = torch.softmax(modelB(xB), dim=1)[0]\n",
    "\n",
    "        a = int(torch.argmax(pA)); b = int(torch.argmax(pB))\n",
    "        ca = float(pA[a]); cb = float(pB[b])\n",
    "\n",
    "        # düşük güven: “uncertain” yazalım (sad’e çakılmayı azaltır)\n",
    "        la = \"uncertain\" if ca < conf_thr else (clsA[a] if clsA else str(a))\n",
    "        lb = \"uncertain\" if cb < conf_thr else (clsB[b] if clsB else str(b))\n",
    "\n",
    "        tA = f\"A:{ckptA.get('optimizer_name','?')} {la} {ca*100:.1f}%\"\n",
    "        tB = f\"B:{ckptB.get('optimizer_name','?')} {lb} {cb*100:.1f}%\"\n",
    "\n",
    "        cv2.putText(frame, tA, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (255,255,0), 2)\n",
    "        cv2.putText(frame, tB, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0,255,255), 2)\n",
    "\n",
    "        cv2.imshow(\"FER live A/B\", frame)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:  # ESC\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "# örnek:\n",
    "webcam_compare(r\".\\runs_cnn\\sgd\\best_sgd.pt\", r\".\\runs_cnn\\karci\\best_karci.pt\")\n"
   ],
   "id": "ba3effe43b8ae380",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC çıkış.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "11) Webcam ile \"seçtiğim.pt\" canlı kıyas (iki modeli aynı anda)",
   "id": "8418e9c1567aabe9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T08:53:25.295058Z",
     "start_time": "2025-12-23T08:52:40.487115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_checkpoint(pt_path):\n",
    "    ckpt = torch.load(pt_path, map_location=device)\n",
    "\n",
    "    # backbone bilgisi ckpt içinde yoksa varsayılan\n",
    "    backbone = ckpt.get(\"backbone\", \"resnet34\")\n",
    "\n",
    "    # bazı ckpt'lerde num_classes yok, o yüzden classes üzerinden çıkaralım\n",
    "    if \"classes\" in ckpt and ckpt[\"classes\"] is not None:\n",
    "        ncls = len(ckpt[\"classes\"])\n",
    "    else:\n",
    "        ncls = num_classes  # senin global num_classes'ın varsa\n",
    "\n",
    "    model = build_model(ncls, backbone=backbone, dropout=0.0).to(device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "    return model, ckpt\n",
    "\n",
    "def preprocess_frame_bgr(frame_bgr):\n",
    "    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    img  = cv2.resize(gray, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    x = torch.from_numpy(img).float() / 255.0\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = x.unsqueeze(0).unsqueeze(0)  # [1,1,H,W]\n",
    "    return x.to(device)\n",
    "\n",
    "def _model_name(ckpt, path):\n",
    "    # ckpt içinde farklı isimlendirmeler olabiliyor\n",
    "    if \"optimizer_name\" in ckpt and ckpt[\"optimizer_name\"]:\n",
    "        return str(ckpt[\"optimizer_name\"]).upper()\n",
    "    if \"optimizer\" in ckpt and ckpt[\"optimizer\"]:\n",
    "        return str(ckpt[\"optimizer\"]).upper()\n",
    "    # yoksa dosya adından\n",
    "    return os.path.splitext(os.path.basename(path))[0].upper()\n",
    "\n",
    "def webcam_compare(pt_path_A, pt_path_B, cam_id=0):\n",
    "    modelA, ckptA = load_checkpoint(pt_path_A)\n",
    "    modelB, ckptB = load_checkpoint(pt_path_B)\n",
    "\n",
    "    # classes güvenli çekelim\n",
    "    clsA = ckptA.get(\"classes\", None)\n",
    "    clsB = ckptB.get(\"classes\", None)\n",
    "\n",
    "    # sınıflar yoksa fallback\n",
    "    if clsA is None and clsB is None:\n",
    "        cls = [str(i) for i in range(num_classes)]\n",
    "    elif clsA is not None and clsB is None:\n",
    "        cls = clsA\n",
    "    elif clsA is None and clsB is not None:\n",
    "        cls = clsB\n",
    "    else:\n",
    "        # ikisi de var, uyuşuyor mu bakalım\n",
    "        if list(clsA) != list(clsB):\n",
    "            print(\"UYARI: A ve B sınıf listeleri farklı! A sınıfları baz alınacak.\")\n",
    "        cls = clsA\n",
    "\n",
    "    nameA = _model_name(ckptA, pt_path_A)\n",
    "    nameB = _model_name(ckptB, pt_path_B)\n",
    "\n",
    "    cap = cv2.VideoCapture(cam_id)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Webcam açılamadı. cam_id=0/1/2 dene, ya da başka uygulama kullanıyor olabilir.\")\n",
    "\n",
    "    print(\"ESC ile çıkış.\")\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        x = preprocess_frame_bgr(frame)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pA = torch.softmax(modelA(x), dim=1)[0].detach().cpu().numpy()\n",
    "            pB = torch.softmax(modelB(x), dim=1)[0].detach().cpu().numpy()\n",
    "\n",
    "        a = int(np.argmax(pA))\n",
    "        b = int(np.argmax(pB))\n",
    "\n",
    "        tA = f\"A:{nameA}  {cls[a]}  {pA[a]*100:.1f}%\"\n",
    "        tB = f\"B:{nameB}  {cls[b]}  {pB[b]*100:.1f}%\"\n",
    "\n",
    "        # yazılar\n",
    "        cv2.putText(frame, tA, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (255,255,0), 2)\n",
    "        cv2.putText(frame, tB, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0,255,255), 2)\n",
    "\n",
    "        cv2.imshow(\"FER live A/B\", frame)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:  # ESC\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# örnek:\n",
    "webcam_compare(r\".\\runs_cnn\\mkarci\\best_mkarci.pt\", r\".\\runs_cnn\\karci\\best_karci.pt\")\n"
   ],
   "id": "81cc367e83643910",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC ile çıkış.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T01:29:17.595670Z",
     "start_time": "2025-12-22T01:29:17.447904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt = torch.load(r\".\\runs_cnn\\karci\\best_karci.pt\", map_location=\"cpu\")\n",
    "print(\"img_size:\", ckpt.get(\"img_size\"))\n",
    "print(\"norm:\", ckpt.get(\"norm\"))\n",
    "print(\"backbone:\", ckpt.get(\"backbone\"))\n"
   ],
   "id": "ab658cee42ce3d06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size: 224\n",
      "norm: None\n",
      "backbone: resnet34\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (CUDA cu118)",
   "language": "python",
   "name": "py310-cu118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
